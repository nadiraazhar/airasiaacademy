# -*- coding: utf-8 -*-
"""Nadira - Project - Web Application for Data Analytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d28u3Q1o-KbBU-yqJxdfEVBW-Vwg9D28

# Project - Web Application for Data Analytics

## About the instructor:

**Ts. Nur Shakirah Md Salleh**

Lead Technical Trainer - Data, Analytic and Machine Learning

airasia academy

nurshakirahmdsalleh@airasiaacademy.com

LinkedIn: [Ts. Nur Shakirah Md Salleh](https://www.linkedin.com/in/nurshakirahmdsalleh)

Â©2023 [airasia academy](https://airasiaacademy.com) All rights reserved.

#Project

Instructions:
1. Develop a Python website to predict the number of sales and deploy it using Streamlit using GitHub repository.
2. You are require to use `Advertising.csv` dataset in this case study. Generate the model of this dataset outside of the streamlit environment (You can use Google Colab). You just need to load the model in this app (no model training should happens in this application).
3. You are require to choose only **ONE** of the most suitable supervised machine learning algorithm to solve this problem.
4. Feature scaling is optional for this project.
5. You need to enable slider to set the feature values.

[Hint: You can use `iris.py` as a guideline for the user interface]

**Submission**

Submit the screenshot of the:
* source code (.py) on GitHub
* streamlit app
"""

#to do:-
#data to use: advertising.csv
#load model in application
#feature scaling is optional
#slider untuk masukkan feature value

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

pd.options.display.max_columns = None
pd.options.display.max_rows = None

#df = pd.read_csv('Advertising.csv')
from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('drive/MyDrive/Advertising.csv') #('drive/MyDrive/ColabDataset/Advertising.csv') #('drive/MyDrive/Folder name/File name.csv')
df.head()

df = df.drop('Unnamed: 0', axis=1)
df.head()

df.describe()

from sklearn import preprocessing
scaler = preprocessing.MinMaxScaler()
scalerSales = preprocessing.MinMaxScaler()      #use later for unscale data

df_sales = pd.DataFrame()
df_sales['Sales'] = df['Sales'].copy()          #use later for unscale data

scaled=scaler.fit_transform(df)
scaledSales=scalerSales.fit_transform(df_sales) #use later for unscale data
df_scaled = pd.DataFrame(scaled)
df_scaled.columns = df.columns
df_scaled.head()

from sklearn.model_selection import train_test_split

X=df_scaled.drop('Sales', axis=1)
y=df_scaled.Sales

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)

print(X_train.shape)
print(y_train.shape)

print(X_test.shape)
print(y_test.shape)

from sklearn.svm import SVR

modelSvr = SVR(kernel='linear', C=3).fit(X_train, y_train) #SVC for classification, SVR untuk regression
y_pred = modelSvr.predict(X_test)

from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# The mean absolute error
print("Mean absolute error: {} ".format(mean_absolute_error(y_test, y_pred)))

# The mean squared error
print("Mean squared error: {} ".format(mean_squared_error(y_test, y_pred)))

# Root mean squared error
print("Root mean squared error: {} ".format(mean_squared_error(y_test, y_pred)**0.5))

# Explained variance score: 1 is perfect prediction
print('Variance score: {} '.format(r2_score(y_test,y_pred)))

df_prediction = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
df_prediction

tempActual = pd.DataFrame()
tempActual['Actual'] = df_prediction['Actual'].copy()

tempPrediction = pd.DataFrame()
tempPrediction['Predicted'] = df_prediction['Predicted'].copy()

df_prediction['Actual'] = scalerSales.inverse_transform(tempActual)
df_prediction['Predicted'] = scalerSales.inverse_transform(tempPrediction)
df_prediction

import pickle

pickle.dump(model, open("AdvertisingRegression.h5", "wb")) #wb: write binary #.h5 extension untuk model

print("model saved")